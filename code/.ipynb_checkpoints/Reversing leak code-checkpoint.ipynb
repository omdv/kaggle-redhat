{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from itertools import product\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolateFun0(x):\n",
    "    \"\"\"Original script author's function rewritten in Python.\n",
    "    The author interpolates between two known values by averaging them. We\n",
    "    can think of this as 0th order interpolation. \"\"\"\n",
    "\n",
    "    ## TODO: This function could use some optimization. The R version is much faster...\n",
    "    x = x.reset_index(drop=True)\n",
    "    g = x['outcome'] ## g should be a list or a pandas Series.\n",
    "    if g.shape[0] < 3: ## If we have at most two rows.\n",
    "        x['filled'] = g ## Will be replaced by a mean.\n",
    "        return x\n",
    "    missing_index = g.isnull()\n",
    "    borders = np.append([g.index[0]], g[~missing_index].index, axis=0)\n",
    "    borders = np.append(borders, [g.index[-1]+1], axis=0)\n",
    "    forward_border = borders[1:]\n",
    "    backward_border = borders[:-1]\n",
    "    forward_border_g = g[forward_border]\n",
    "    backward_border_g = g[backward_border]\n",
    "    ## Interpolate borders.\n",
    "    ## TODO: Why does the script author use the value 0.1?\n",
    "    border_fill = 0.1\n",
    "    forward_border_g[forward_border_g.index[-1]] = abs(forward_border_g[forward_border_g.index[-2]]-border_fill)\n",
    "    backward_border_g[backward_border_g.index[0]] = abs(forward_border_g[forward_border_g.index[0]]-border_fill)\n",
    "    times = forward_border-backward_border\n",
    "    forward_x_fill = np.repeat(forward_border_g, times).reset_index(drop=True)\n",
    "    backward_x_fill = np.repeat(backward_border_g, times).reset_index(drop=True)\n",
    "    vec = (forward_x_fill+backward_x_fill)/2\n",
    "    g[missing_index] = vec[missing_index] ## Impute missing values only.\n",
    "    x['filled'] = g\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl = pd.read_csv('../input/people.csv')\n",
    "\n",
    "# Convert booleans to integers.\n",
    "p_logi = ppl.select_dtypes(include=['bool']).columns\n",
    "ppl[p_logi] = ppl[p_logi].astype('int')\n",
    "del p_logi\n",
    "\n",
    "# Transform date.\n",
    "ppl['date'] = pd.to_datetime(ppl['date'])\n",
    "\n",
    "# Load activities.--------------------------------------------------------------\n",
    "# Read and combine.\n",
    "activs = pd.read_csv('../input/act_train.csv')\n",
    "TestActivs = pd.read_csv('../input/act_test.csv')\n",
    "TestActivs['outcome'] = np.nan ## Add the missing column to the test set.\n",
    "activs = pd.concat([activs, TestActivs], axis=0) ## Append train and test sets.\n",
    "del TestActivs\n",
    "\n",
    "# Extract only required variables.\n",
    "activs = activs[['people_id', 'outcome', 'activity_id', 'date']] ## Let's look at these columns only.\n",
    "\n",
    "# Merge people data into activities.\n",
    "## This keeps all the rows from activities.\n",
    "## TODO: We are not using rows from ppl who have no activities...\n",
    "d1 = pd.merge(activs, ppl, on='people_id', how='right')\n",
    "\n",
    "## These are the indices of the rows from the test set.\n",
    "testset = ppl[ppl['people_id'].isin(d1[d1['outcome'].isnull()]['people_id'])].index\n",
    "\n",
    "d1['activdate'] = pd.to_datetime(d1['date_x'])\n",
    "\n",
    "del activs\n",
    "\n",
    "# Prepare grid for prediction. -------------------------------------------------\n",
    "\n",
    "# Create all group_1/day grid.\n",
    "minactivdate = min(d1['activdate'])\n",
    "maxactivdate = max(d1['activdate'])\n",
    "\n",
    "## Make a list of all days from min to max.\n",
    "alldays = [maxactivdate - datetime.timedelta(days=x) for x in range(0, (maxactivdate - minactivdate).days+1)][::-1]\n",
    "\n",
    "## Take the values of group_1 from the rows of d1 which do not belong to the test set.\n",
    "grid_left = set(d1[~d1['people_id'].isin(ppl.iloc[testset]['people_id'])]['group_1'])\n",
    "## Take cartesian product between the above variable and the list of all days.\n",
    "## I think in the original script author thinks of the values in group_1 as companies.\n",
    "allCompaniesAndDays = pd.DataFrame.from_records(product(grid_left, alldays))\n",
    "\n",
    "# Nicer names.\n",
    "allCompaniesAndDays.columns = ['group_1', 'date_p']\n",
    "\n",
    "# Sort it.\n",
    "allCompaniesAndDays.sort_values(['group_1', 'date_p'], inplace=True)\n",
    "\n",
    "## This is what allCompaniesAndDays looks like so far.\n",
    "\"\"\"\n",
    ">>> allCompaniesAndDays.sample(n=10)\n",
    "              group_1     date_p\n",
    "10318543  group 14386 2023-08-09\n",
    "3470112    group 8767 2022-08-25\n",
    "5542924   group 30061 2023-01-11\n",
    "2328370   group 39750 2022-09-10\n",
    "7764760    group 1175 2022-12-12\n",
    "4788523    group 3788 2023-07-25\n",
    "5545711   group 12085 2022-10-13\n",
    "859359    group 28900 2023-07-21\n",
    "11188454  group 21110 2023-02-14\n",
    "9277889   group 26980 2023-08-07\n",
    "\"\"\"\n",
    "\n",
    "# What are values on days where we have data?\n",
    "## For a combination of group_1 and activdate, calculate the mean of the outcome variable.\n",
    "meanbycomdate = d1[~d1['people_id'].isin(ppl.iloc[testset]['people_id'])].\\\n",
    "    groupby(['group_1', 'activdate'])['outcome'].agg('mean')\n",
    "## Convert the calculation into a proper DataFrame.\n",
    "meanbycomdate = meanbycomdate.to_frame().reset_index()\n",
    "\n",
    "# Add them to full data grid.\n",
    "allCompaniesAndDays = pd.merge(allCompaniesAndDays, meanbycomdate, left_on=['group_1', 'date_p'],\\\n",
    "                                right_on=['group_1', 'activdate'], how='left')\n",
    "allCompaniesAndDays.drop('activdate', axis=1, inplace=True)\n",
    "allCompaniesAndDays.sort_values(['group_1', 'date_p'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
